{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPKHrUzcn2u+2Vx9u1xBp1I"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Tensor**"
      ],
      "metadata": {
        "id": "j0bidD3dCdY-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3YClW8klATIh",
        "outputId": "69e93ff8-c9df-4649-b0b7-a50dff89ceb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3.5353e+34])\n",
            "tensor([2.5047e-34, 0.0000e+00, 2.5045e-34])\n",
            "tensor([[ 2.5053e-34,  0.0000e+00, -3.0796e-18],\n",
            "        [ 4.5836e-41,  8.9683e-44,  0.0000e+00]])\n",
            "tensor([[[ 2.5059e-34,  0.0000e+00, -3.0796e-18],\n",
            "         [ 4.5836e-41,  8.9683e-44,  0.0000e+00]],\n",
            "\n",
            "        [[ 1.1210e-43,  0.0000e+00,  2.5051e-34],\n",
            "         [ 0.0000e+00,  1.3563e-19,  1.3563e-19]]])\n",
            "tensor([[0.0745, 0.3935, 0.5526],\n",
            "        [0.8975, 0.6041, 0.6600],\n",
            "        [0.9554, 0.8319, 0.0601],\n",
            "        [0.5868, 0.4021, 0.4540],\n",
            "        [0.4162, 0.0702, 0.6944]])\n",
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "torch.Size([5, 3])\n",
            "torch.float32\n",
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.]], dtype=torch.float16)\n",
            "torch.float16\n",
            "torch.Size([2])\n",
            "tensor([[0.2408, 0.6317, 0.8486],\n",
            "        [0.1723, 0.3239, 0.1711],\n",
            "        [0.1946, 0.4930, 0.4415],\n",
            "        [0.7606, 0.1840, 0.9087],\n",
            "        [0.0750, 0.7158, 0.6711]])\n",
            "tensor([0.2408, 0.1723, 0.1946, 0.7606, 0.0750])\n",
            "tensor([0.1723, 0.3239, 0.1711])\n",
            "tensor(0.3239)\n",
            "0.32390666007995605\n",
            "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n",
            "tensor([1., 1., 1., 1., 1.])\n",
            "[1. 1. 1. 1. 1.]\n",
            "<class 'numpy.ndarray'>\n",
            "tensor([2., 2., 2., 2., 2.])\n",
            "[2. 2. 2. 2. 2.]\n",
            "[1. 1. 1. 1. 1.]\n",
            "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
            "[2. 2. 2. 2. 2.]\n",
            "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Everything in pytorch is based on Tensor operations.\n",
        "# A tensor can have different dimensions\n",
        "# so it can be 1d, 2d, or even 3d and higher\n",
        "\n",
        "# scalar, vector, matrix, tensor\n",
        "\n",
        "# torch.empty(size): uninitiallized\n",
        "x = torch.empty(1) # scalar\n",
        "print(x)\n",
        "x = torch.empty(3) # vector, 1D\n",
        "print(x)\n",
        "x = torch.empty(2,3) # matrix, 2D\n",
        "print(x)\n",
        "x = torch.empty(2,2,3) # tensor, 3 dimensions\n",
        "#x = torch.empty(2,2,2,3) # tensor, 4 dimensions\n",
        "print(x)\n",
        "\n",
        "# torch.rand(size): random numbers [0, 1]\n",
        "x = torch.rand(5, 3)\n",
        "print(x)\n",
        "\n",
        "# torch.zeros(size), fill with 0\n",
        "# torch.ones(size), fill with 1\n",
        "x = torch.zeros(5, 3)\n",
        "print(x)\n",
        "\n",
        "# check size\n",
        "print(x.size())\n",
        "\n",
        "# check data type\n",
        "print(x.dtype)\n",
        "\n",
        "# specify types, float32 default\n",
        "x = torch.zeros(5, 3, dtype=torch.float16)\n",
        "print(x)\n",
        "\n",
        "# check type\n",
        "print(x.dtype)\n",
        "\n",
        "# construct from data\n",
        "x = torch.tensor([5.5, 3])\n",
        "print(x.size())\n",
        "\n",
        "# requires_grad argument\n",
        "# This will tell pytorch that it will need to calculate the gradients for this tensor\n",
        "# later in your optimization steps\n",
        "# i.e. this is a variable in your model that you want to optimize\n",
        "x = torch.tensor([5.5, 3], requires_grad=True)\n",
        "\n",
        "# Operations\n",
        "y = torch.rand(2, 2)\n",
        "x = torch.rand(2, 2)\n",
        "\n",
        "# elementwise addition\n",
        "z = x + y\n",
        "# torch.add(x,y)\n",
        "\n",
        "# in place addition, everythin with a trailing underscore is an inplace operation\n",
        "# i.e. it will modify the variable\n",
        "# y.add_(x)\n",
        "\n",
        "# substraction\n",
        "z = x - y\n",
        "z = torch.sub(x, y)\n",
        "\n",
        "# multiplication\n",
        "z = x * y\n",
        "z = torch.mul(x,y)\n",
        "\n",
        "# division\n",
        "z = x / y\n",
        "z = torch.div(x,y)\n",
        "\n",
        "# Slicing\n",
        "x = torch.rand(5,3)\n",
        "print(x)\n",
        "print(x[:, 0]) # all rows, column 0\n",
        "print(x[1, :]) # row 1, all columns\n",
        "print(x[1,1]) # element at 1, 1\n",
        "\n",
        "# Get the actual value if only 1 element in your tensor\n",
        "print(x[1,1].item())\n",
        "\n",
        "# Reshape with torch.view()\n",
        "x = torch.randn(4, 4)\n",
        "y = x.view(16)\n",
        "z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
        "# if -1 it pytorch will automatically determine the necessary size\n",
        "print(x.size(), y.size(), z.size())\n",
        "\n",
        "# Numpy\n",
        "# Converting a Torch Tensor to a NumPy array and vice versa is very easy\n",
        "a = torch.ones(5)\n",
        "print(a)\n",
        "\n",
        "# torch to numpy with .numpy()\n",
        "b = a.numpy()\n",
        "print(b)\n",
        "print(type(b))\n",
        "\n",
        "# Carful: If the Tensor is on the CPU (not the GPU),\n",
        "# both objects will share the same memory location, so changing one\n",
        "# will also change the other\n",
        "a.add_(1)\n",
        "print(a)\n",
        "print(b)\n",
        "\n",
        "# numpy to torch with .from_numpy(x)\n",
        "import numpy as np\n",
        "a = np.ones(5)\n",
        "b = torch.from_numpy(a)\n",
        "print(a)\n",
        "print(b)\n",
        "\n",
        "# again be careful when modifying\n",
        "a += 1\n",
        "print(a)\n",
        "print(b)\n",
        "\n",
        "# by default all tensors are created on the CPU,\n",
        "# but you can also move them to the GPU (only if it's available )\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")          # a CUDA device object\n",
        "    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n",
        "    x = x.to(device)                       # or just use strings ``.to(\"cuda\")``\n",
        "    z = x + y\n",
        "    # z = z.numpy() # not possible because numpy cannot handle GPU tenors\n",
        "    # move to CPU again\n",
        "    z.to(\"cpu\")       # ``.to`` can also change dtype together!\n",
        "    # z = z.numpy()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "AUTOGRAD"
      ],
      "metadata": {
        "id": "tWfB_L9lCkhc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# The autograd package provides automatic differentiation\n",
        "# for all operations on Tensors\n",
        "\n",
        "# requires_grad = True -> tracks all operations on the tensor.\n",
        "x = torch.randn(3, requires_grad=True)\n",
        "y = x + 2\n",
        "\n",
        "# y was created as a result of an operation, so it has a grad_fn attribute.\n",
        "# grad_fn: references a Function that has created the Tensor\n",
        "print(x) # created by the user -> grad_fn is None\n",
        "print(y)\n",
        "print(y.grad_fn)\n",
        "\n",
        "# Do more operations on y\n",
        "z = y * y * 3\n",
        "print(z)\n",
        "z = z.mean()\n",
        "print(z)\n",
        "\n",
        "# Let's compute the gradients with backpropagation\n",
        "# When we finish our computation we can call .backward() and have all the gradients computed automatically.\n",
        "# The gradient for this tensor will be accumulated into .grad attribute.\n",
        "# It is the partial derivate of the function w.r.t. the tensor\n",
        "\n",
        "z.backward()\n",
        "print(x.grad) # dz/dx\n",
        "\n",
        "# Generally speaking, torch.autograd is an engine for computing vector-Jacobian product\n",
        "# It computes partial derivates while applying the chain rule\n",
        "\n",
        "# -------------\n",
        "# Model with non-scalar output:\n",
        "# If a Tensor is non-scalar (more than 1 elements), we need to specify arguments for backward()\n",
        "# specify a gradient argument that is a tensor of matching shape.\n",
        "# needed for vector-Jacobian product\n",
        "\n",
        "x = torch.randn(3, requires_grad=True)\n",
        "\n",
        "y = x * 2\n",
        "for _ in range(10):\n",
        "    y = y * 2\n",
        "\n",
        "print(y)\n",
        "print(y.shape)\n",
        "\n",
        "v = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float32)\n",
        "y.backward(v)\n",
        "print(x.grad)\n",
        "\n",
        "# -------------\n",
        "# Stop a tensor from tracking history:\n",
        "# For example during our training loop when we want to update our weights\n",
        "# then this update operation should not be part of the gradient computation\n",
        "# - x.requires_grad_(False)\n",
        "# - x.detach()\n",
        "# - wrap in 'with torch.no_grad():'\n",
        "\n",
        "# .requires_grad_(...) changes an existing flag in-place.\n",
        "a = torch.randn(2, 2)\n",
        "print(a.requires_grad)\n",
        "b = ((a * 3) / (a - 1))\n",
        "print(b.grad_fn)\n",
        "a.requires_grad_(True)\n",
        "print(a.requires_grad)\n",
        "b = (a * a).sum()\n",
        "print(b.grad_fn)\n",
        "\n",
        "# .detach(): get a new Tensor with the same content but no gradient computation:\n",
        "a = torch.randn(2, 2, requires_grad=True)\n",
        "print(a.requires_grad)\n",
        "b = a.detach()\n",
        "print(b.requires_grad)\n",
        "\n",
        "# wrap in 'with torch.no_grad():'\n",
        "a = torch.randn(2, 2, requires_grad=True)\n",
        "print(a.requires_grad)\n",
        "with torch.no_grad():\n",
        "    print((x ** 2).requires_grad)\n",
        "\n",
        "# -------------\n",
        "# backward() accumulates the gradient for this tensor into .grad attribute.\n",
        "# !!! We need to be careful during optimization !!!\n",
        "# Use .zero_() to empty the gradients before a new optimization step!\n",
        "weights = torch.ones(4, requires_grad=True)\n",
        "\n",
        "for epoch in range(3):\n",
        "    # just a dummy example\n",
        "    model_output = (weights*3).sum()\n",
        "    model_output.backward()\n",
        "\n",
        "    print(weights.grad)\n",
        "\n",
        "    # optimize model, i.e. adjust weights...\n",
        "    with torch.no_grad():\n",
        "        weights -= 0.1 * weights.grad\n",
        "\n",
        "    # this is important! It affects the final weights & output\n",
        "    weights.grad.zero_()\n",
        "\n",
        "print(weights)\n",
        "print(model_output)\n",
        "\n",
        "# Optimizer has zero_grad() method\n",
        "# optimizer = torch.optim.SGD([weights], lr=0.1)\n",
        "# During training:\n",
        "# optimizer.step()\n",
        "# optimizer.zero_grad()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gADrH5HiCIj_",
        "outputId": "711ab2dc-2449-43d3-83f5-def09603cc3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.8040, 1.0896, 0.1567], requires_grad=True)\n",
            "tensor([2.8040, 3.0896, 2.1567], grad_fn=<AddBackward0>)\n",
            "<AddBackward0 object at 0x7fc690dc1600>\n",
            "tensor([23.5872, 28.6361, 13.9538], grad_fn=<MulBackward0>)\n",
            "tensor(22.0590, grad_fn=<MeanBackward0>)\n",
            "tensor([5.6080, 6.1791, 4.3134])\n",
            "tensor([  659.9194, -1044.7303, -2857.5830], grad_fn=<MulBackward0>)\n",
            "torch.Size([3])\n",
            "tensor([2.0480e+02, 2.0480e+03, 2.0480e-01])\n",
            "False\n",
            "None\n",
            "True\n",
            "<SumBackward0 object at 0x7fc690dc23e0>\n",
            "True\n",
            "False\n",
            "True\n",
            "False\n",
            "tensor([3., 3., 3., 3.])\n",
            "tensor([3., 3., 3., 3.])\n",
            "tensor([3., 3., 3., 3.])\n",
            "tensor([0.1000, 0.1000, 0.1000, 0.1000], requires_grad=True)\n",
            "tensor(4.8000, grad_fn=<SumBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Backpropagation"
      ],
      "metadata": {
        "id": "QYexaMohCojh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "x = torch.tensor(1.0)\n",
        "y = torch.tensor(2.0)\n",
        "\n",
        "# This is the parameter we want to optimize -> requires_grad=True\n",
        "w = torch.tensor(1.0, requires_grad=True)\n",
        "\n",
        "# forward pass to compute loss\n",
        "y_predicted = w * x\n",
        "loss = (y_predicted - y)**2\n",
        "print(loss)\n",
        "\n",
        "# backward pass to compute gradient dLoss/dw\n",
        "loss.backward()\n",
        "print(w.grad)\n",
        "\n",
        "# update weights\n",
        "# next forward and backward pass...\n",
        "\n",
        "# continue optimizing:\n",
        "# update weights, this operation should not be part of the computational graph\n",
        "with torch.no_grad():\n",
        "    w -= 0.01 * w.grad\n",
        "# don't forget to zero the gradients\n",
        "w.grad.zero_()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQPxdpm3COsE",
        "outputId": "c4e8e76f-4b29-4503-f5b1-fddeb20db2a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1., grad_fn=<PowBackward0>)\n",
            "tensor(-2.)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradient Descent Auto"
      ],
      "metadata": {
        "id": "FPq80wx4CtwQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Here we replace the manually computed gradient with autograd\n",
        "\n",
        "# Linear regression\n",
        "# f = w * x\n",
        "\n",
        "# here : f = 2 * x\n",
        "X = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\n",
        "Y = torch.tensor([2, 4, 6, 8], dtype=torch.float32)\n",
        "\n",
        "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
        "\n",
        "# model output\n",
        "def forward(x):\n",
        "    return w * x\n",
        "\n",
        "# loss = MSE\n",
        "def loss(y, y_pred):\n",
        "    return ((y_pred - y)**2).mean()\n",
        "\n",
        "print(f'Prediction before training: f(5) = {forward(5).item():.3f}')\n",
        "\n",
        "# Training\n",
        "learning_rate = 0.01\n",
        "n_iters = 100\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "    # predict = forward pass\n",
        "    y_pred = forward(X)\n",
        "\n",
        "    # loss\n",
        "    l = loss(Y, y_pred)\n",
        "\n",
        "    # calculate gradients = backward pass\n",
        "    l.backward()\n",
        "\n",
        "    # update weights\n",
        "    #w.data = w.data - learning_rate * w.grad\n",
        "    with torch.no_grad():\n",
        "        w -= learning_rate * w.grad\n",
        "\n",
        "    # zero the gradients after updating\n",
        "    w.grad.zero_()\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        print(f'epoch {epoch+1}: w = {w.item():.3f}, loss = {l.item():.8f}')\n",
        "\n",
        "print(f'Prediction after training: f(5) = {forward(5).item():.3f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ViM-sb8fCxfi",
        "outputId": "77f29462-c1ef-4135-f9d4-16534b24d62e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction before training: f(5) = 0.000\n",
            "epoch 1: w = 0.300, loss = 30.00000000\n",
            "epoch 11: w = 1.665, loss = 1.16278565\n",
            "epoch 21: w = 1.934, loss = 0.04506890\n",
            "epoch 31: w = 1.987, loss = 0.00174685\n",
            "epoch 41: w = 1.997, loss = 0.00006770\n",
            "epoch 51: w = 1.999, loss = 0.00000262\n",
            "epoch 61: w = 2.000, loss = 0.00000010\n",
            "epoch 71: w = 2.000, loss = 0.00000000\n",
            "epoch 81: w = 2.000, loss = 0.00000000\n",
            "epoch 91: w = 2.000, loss = 0.00000000\n",
            "Prediction after training: f(5) = 10.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Loss & Optimizer"
      ],
      "metadata": {
        "id": "bHvwaNdFC09T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Linear regression\n",
        "# f = w * x\n",
        "\n",
        "# here : f = 2 * x\n",
        "\n",
        "# 0) Training samples, watch the shape!\n",
        "X = torch.tensor([[1], [2], [3], [4]], dtype=torch.float32)\n",
        "Y = torch.tensor([[2], [4], [6], [8]], dtype=torch.float32)\n",
        "\n",
        "n_samples, n_features = X.shape\n",
        "print(f'#samples: {n_samples}, #features: {n_features}')\n",
        "# 0) create a test sample\n",
        "X_test = torch.tensor([5], dtype=torch.float32)\n",
        "\n",
        "# 1) Design Model, the model has to implement the forward pass!\n",
        "# Here we can use a built-in model from PyTorch\n",
        "input_size = n_features\n",
        "output_size = n_features\n",
        "\n",
        "# we can call this model with samples X\n",
        "model = nn.Linear(input_size, output_size)\n",
        "\n",
        "'''\n",
        "class LinearRegression(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(LinearRegression, self).__init__()\n",
        "        # define diferent layers\n",
        "        self.lin = nn.Linear(input_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.lin(x)\n",
        "\n",
        "model = LinearRegression(input_size, output_size)\n",
        "'''\n",
        "\n",
        "print(f'Prediction before training: f(5) = {model(X_test).item():.3f}')\n",
        "\n",
        "# 2) Define loss and optimizer\n",
        "learning_rate = 0.01\n",
        "n_iters = 100\n",
        "\n",
        "loss = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# 3) Training loop\n",
        "for epoch in range(n_iters):\n",
        "    # predict = forward pass with our model\n",
        "    y_predicted = model(X)\n",
        "\n",
        "    # loss\n",
        "    l = loss(Y, y_predicted)\n",
        "\n",
        "    # calculate gradients = backward pass\n",
        "    l.backward()\n",
        "\n",
        "    # update weights\n",
        "    optimizer.step()\n",
        "\n",
        "    # zero the gradients after updating\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        [w, b] = model.parameters() # unpack parameters\n",
        "        print('epoch ', epoch+1, ': w = ', w[0][0].item(), ' loss = ', l)\n",
        "\n",
        "print(f'Prediction after training: f(5) = {model(X_test).item():.3f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2bCATCXC8Mx",
        "outputId": "530ac298-7a24-49ef-ea0c-5c866cea344b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#samples: 4, #features: 1\n",
            "Prediction before training: f(5) = -3.252\n",
            "epoch  1 : w =  -0.29202908277511597  loss =  tensor(51.7500, grad_fn=<MseLossBackward0>)\n",
            "epoch  11 : w =  1.3626881837844849  loss =  tensor(1.4854, grad_fn=<MseLossBackward0>)\n",
            "epoch  21 : w =  1.6367828845977783  loss =  tensor(0.1764, grad_fn=<MseLossBackward0>)\n",
            "epoch  31 : w =  1.688571810722351  loss =  tensor(0.1345, grad_fn=<MseLossBackward0>)\n",
            "epoch  41 : w =  1.7043755054473877  loss =  tensor(0.1258, grad_fn=<MseLossBackward0>)\n",
            "epoch  51 : w =  1.7141703367233276  loss =  tensor(0.1185, grad_fn=<MseLossBackward0>)\n",
            "epoch  61 : w =  1.722784161567688  loss =  tensor(0.1116, grad_fn=<MseLossBackward0>)\n",
            "epoch  71 : w =  1.731000304222107  loss =  tensor(0.1051, grad_fn=<MseLossBackward0>)\n",
            "epoch  81 : w =  1.7389506101608276  loss =  tensor(0.0990, grad_fn=<MseLossBackward0>)\n",
            "epoch  91 : w =  1.7466626167297363  loss =  tensor(0.0932, grad_fn=<MseLossBackward0>)\n",
            "Prediction after training: f(5) = 9.492\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear Regression"
      ],
      "metadata": {
        "id": "xaEtioq-C9Up"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 0) Prepare data\n",
        "X_numpy, y_numpy = datasets.make_regression(n_samples=100, n_features=1, noise=20, random_state=4)\n",
        "\n",
        "# cast to float Tensor\n",
        "X = torch.from_numpy(X_numpy.astype(np.float32))\n",
        "y = torch.from_numpy(y_numpy.astype(np.float32))\n",
        "y = y.view(y.shape[0], 1)\n",
        "\n",
        "n_samples, n_features = X.shape\n",
        "\n",
        "# 1) Model\n",
        "# Linear model f = wx + b\n",
        "input_size = n_features\n",
        "output_size = 1\n",
        "model = nn.Linear(input_size, output_size)\n",
        "\n",
        "# 2) Loss and optimizer\n",
        "learning_rate = 0.01\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# 3) Training loop\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "    # Forward pass and loss\n",
        "    y_predicted = model(X)\n",
        "    loss = criterion(y_predicted, y)\n",
        "\n",
        "    # Backward pass and update\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # zero grad before new step\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f'epoch: {epoch+1}, loss = {loss.item():.4f}')\n",
        "\n",
        "# Plot\n",
        "predicted = model(X).detach().numpy()\n",
        "\n",
        "plt.plot(X_numpy, y_numpy, 'ro')\n",
        "plt.plot(X_numpy, predicted, 'b')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 604
        },
        "id": "6IHb1b1sC_f2",
        "outputId": "98b372ab-0fc2-4482-da39-94f59996dcda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 10, loss = 3967.2991\n",
            "epoch: 20, loss = 2797.4207\n",
            "epoch: 30, loss = 2000.0944\n",
            "epoch: 40, loss = 1456.5621\n",
            "epoch: 50, loss = 1085.9596\n",
            "epoch: 60, loss = 833.2153\n",
            "epoch: 70, loss = 660.8128\n",
            "epoch: 80, loss = 543.1897\n",
            "epoch: 90, loss = 462.9246\n",
            "epoch: 100, loss = 408.1419\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Regresion"
      ],
      "metadata": {
        "id": "rdAVxY3eDCgO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 0) Prepare data\n",
        "bc = datasets.load_breast_cancer()\n",
        "X, y = bc.data, bc.target\n",
        "\n",
        "n_samples, n_features = X.shape\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\n",
        "\n",
        "# scale\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "X_train = torch.from_numpy(X_train.astype(np.float32))\n",
        "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
        "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
        "y_test = torch.from_numpy(y_test.astype(np.float32))\n",
        "\n",
        "y_train = y_train.view(y_train.shape[0], 1)\n",
        "y_test = y_test.view(y_test.shape[0], 1)\n",
        "\n",
        "# 1) Model\n",
        "# Linear model f = wx + b , sigmoid at the end\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, n_input_features):\n",
        "        super(Model, self).__init__()\n",
        "        self.linear = nn.Linear(n_input_features, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        y_pred = torch.sigmoid(self.linear(x))\n",
        "        return y_pred\n",
        "\n",
        "model = Model(n_features)\n",
        "\n",
        "# 2) Loss and optimizer\n",
        "num_epochs = 100\n",
        "learning_rate = 0.01\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# 3) Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    # Forward pass and loss\n",
        "    y_pred = model(X_train)\n",
        "    loss = criterion(y_pred, y_train)\n",
        "\n",
        "    # Backward pass and update\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # zero grad before new step\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f'epoch: {epoch+1}, loss = {loss.item():.4f}')\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    y_predicted = model(X_test)\n",
        "    y_predicted_cls = y_predicted.round()\n",
        "    acc = y_predicted_cls.eq(y_test).sum() / float(y_test.shape[0])\n",
        "    print(f'accuracy: {acc.item():.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "loEIFanmDFF4",
        "outputId": "f072564d-5230-4e31-f3d0-b803e4d97a67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 10, loss = 0.4398\n",
            "epoch: 20, loss = 0.3820\n",
            "epoch: 30, loss = 0.3416\n",
            "epoch: 40, loss = 0.3116\n",
            "epoch: 50, loss = 0.2883\n",
            "epoch: 60, loss = 0.2697\n",
            "epoch: 70, loss = 0.2544\n",
            "epoch: 80, loss = 0.2415\n",
            "epoch: 90, loss = 0.2305\n",
            "epoch: 100, loss = 0.2210\n",
            "accuracy: 0.9123\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset and Dataloader"
      ],
      "metadata": {
        "id": "b7K4omjxDJWO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "class WineDataset(Dataset):\n",
        "    def __init__(self):\n",
        "        # data loading\n",
        "        xy = np.loadtxt('wine.csv', delimiter=\",\", dtype=np.float32, skiprows=1)\n",
        "        self.x = torch.from_numpy(xy[:, 1:])\n",
        "        self.y = torch.from_numpy(xy[:, [0]])\n",
        "        self.n_samples = xy.shape[0]\n",
        "    def __getitem__(self, index):\n",
        "        return self.x[index], self.y[index]\n",
        "    def __len__(self):\n",
        "        return self.n_samples\n",
        "\n",
        "dataset = WineDataset()\n",
        "dataloader = DataLoader(dataset=dataset, batch_size=4, shuffle=True, num_workers=0)\n",
        "\n",
        "# datater = iter(dataloader)\n",
        "# data = next(datater)\n",
        "# features, labels = data\n",
        "# print(features, labels)\n",
        "\n",
        "# training loop\n",
        "num_epochs = 2\n",
        "total_samples = len(dataset)\n",
        "n_iterations = math.ceil(total_samples/4)\n",
        "print(total_samples, n_iterations)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (inputs, labels) in enumerate(dataloader):\n",
        "        # forward backward, update\n",
        "        if (i+1) % 5 == 0:\n",
        "            print(f'epoch {epoch+1}/{num_epochs}, step {i+1}/{n_iterations}, inputs {inputs.shape}')\n",
        "\n",
        "# fashion-mnist, cifar, coco\n",
        "torchvision.datasets.MNIST()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "dW0ItFMvDMlC",
        "outputId": "705ef375-4fdf-4549-b518-dab9f5910fa1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-b27bbb64801c>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWineDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-b27bbb64801c>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m# data loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mxy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'wine.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskiprows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows, like)\u001b[0m\n\u001b[1;32m   1040\u001b[0m             \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_string_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1042\u001b[0;31m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_datasource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1043\u001b[0m             \u001b[0mfencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'encoding'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m             \u001b[0mline_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataSource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnewline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[1;32m    530\u001b[0m                                       encoding=encoding, newline=newline)\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{path} not found.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: wine.csv not found."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset Transforms"
      ],
      "metadata": {
        "id": "qr5eSeOBDRSS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class WineDataset(Dataset):\n",
        "\n",
        "    def __init__(self, transform=None):\n",
        "        xy = np.loadtxt('/content/wine.csv', delimiter=',', dtype=np.float32, skiprows=1)\n",
        "        self.n_samples = xy.shape[0]\n",
        "\n",
        "        # note that we do not convert to tensor here\n",
        "        self.x_data = xy[:, 1:]\n",
        "        self.y_data = xy[:, [0]]\n",
        "\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        sample = self.x_data[index], self.y_data[index]\n",
        "\n",
        "        if self.transform:\n",
        "            sample = self.transform(sample)\n",
        "\n",
        "        return sample\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n_samples\n",
        "\n",
        "# Custom Transforms\n",
        "# implement __call__(self, sample)\n",
        "class ToTensor:\n",
        "    # Convert ndarrays to Tensors\n",
        "    def __call__(self, sample):\n",
        "        inputs, targets = sample\n",
        "        return torch.from_numpy(inputs), torch.from_numpy(targets)\n",
        "\n",
        "class MulTransform:\n",
        "    # multiply inputs with a given factor\n",
        "    def __init__(self, factor):\n",
        "        self.factor = factor\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        inputs, targets = sample\n",
        "        inputs *= self.factor\n",
        "        return inputs, targets\n",
        "\n",
        "print('Without Transform')\n",
        "dataset = WineDataset()\n",
        "first_data = dataset[0]\n",
        "features, labels = first_data\n",
        "print(type(features), type(labels))\n",
        "print(features, labels)\n",
        "\n",
        "print('\\nWith Tensor Transform')\n",
        "dataset = WineDataset(transform=ToTensor())\n",
        "first_data = dataset[0]\n",
        "features, labels = first_data\n",
        "print(type(features), type(labels))\n",
        "print(features, labels)\n",
        "\n",
        "print('\\nWith Tensor and Multiplication Transform')\n",
        "composed = torchvision.transforms.Compose([ToTensor(), MulTransform(4)])\n",
        "dataset = WineDataset(transform=composed)\n",
        "first_data = dataset[0]\n",
        "features, labels = first_data\n",
        "print(type(features), type(labels))\n",
        "print(features, labels)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "ir5Lq7FDDWK3",
        "outputId": "3c368682-9243-44cc-f911-4e7e9d2088c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Without Transform\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-11c96d04891e>\u001b[0m in \u001b[0;36m<cell line: 49>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Without Transform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWineDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0mfirst_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfirst_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-11c96d04891e>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, transform)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mxy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/wine.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskiprows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows, like)\u001b[0m\n\u001b[1;32m   1040\u001b[0m             \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_string_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1042\u001b[0;31m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_datasource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1043\u001b[0m             \u001b[0mfencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'encoding'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m             \u001b[0mline_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataSource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnewline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[1;32m    530\u001b[0m                                       encoding=encoding, newline=newline)\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{path} not found.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: /content/wine.csv not found."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Softmax and Crossentropy"
      ],
      "metadata": {
        "id": "gPHqcLyjDXhb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "def softmax(x):\n",
        "    return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
        "\n",
        "x = np.array([2.0, 1.0, 0.1])\n",
        "outputs = softmax(x)\n",
        "print('softmax numpy:', outputs)\n",
        "\n",
        "x = torch.tensor([2.0, 1.0, 0.1])\n",
        "outputs = torch.softmax(x, dim=0) # along values along first axis\n",
        "print('softmax torch:', outputs)\n",
        "\n",
        "# Cross entropy\n",
        "# Cross-entropy loss, or log loss, measures the performance of a classification model\n",
        "# whose output is a probability value between 0 and 1.\n",
        "# -> loss increases as the predicted probability diverges from the actual label\n",
        "def cross_entropy(actual, predicted):\n",
        "    EPS = 1e-15\n",
        "    predicted = np.clip(predicted, EPS, 1 - EPS)\n",
        "    loss = -np.sum(actual * np.log(predicted))\n",
        "    return loss # / float(predicted.shape[0])\n",
        "\n",
        "# y must be one hot encoded\n",
        "# if class 0: [1 0 0]\n",
        "# if class 1: [0 1 0]\n",
        "# if class 2: [0 0 1]\n",
        "Y = np.array([1, 0, 0])\n",
        "Y_pred_good = np.array([0.7, 0.2, 0.1])\n",
        "Y_pred_bad = np.array([0.1, 0.3, 0.6])\n",
        "l1 = cross_entropy(Y, Y_pred_good)\n",
        "l2 = cross_entropy(Y, Y_pred_bad)\n",
        "print(f'Loss1 numpy: {l1:.4f}')\n",
        "print(f'Loss2 numpy: {l2:.4f}')\n",
        "\n",
        "# CrossEntropyLoss in PyTorch (applies Softmax)\n",
        "# nn.LogSoftmax + nn.NLLLoss\n",
        "# NLLLoss = negative log likelihood loss\n",
        "loss = nn.CrossEntropyLoss()\n",
        "# loss(input, target)\n",
        "\n",
        "# target is of size nSamples = 1\n",
        "# each element has class label: 0, 1, or 2\n",
        "# Y (=target) contains class labels, not one-hot\n",
        "Y = torch.tensor([0])\n",
        "\n",
        "# input is of size nSamples x nClasses = 1 x 3\n",
        "# y_pred (=input) must be raw, unnormalizes scores (logits) for each class, not softmax\n",
        "Y_pred_good = torch.tensor([[2.0, 1.0, 0.1]])\n",
        "Y_pred_bad = torch.tensor([[0.5, 2.0, 0.3]])\n",
        "l1 = loss(Y_pred_good, Y)\n",
        "l2 = loss(Y_pred_bad, Y)\n",
        "\n",
        "print(f'PyTorch Loss1: {l1.item():.4f}')\n",
        "print(f'PyTorch Loss2: {l2.item():.4f}')\n",
        "\n",
        "# get predictions\n",
        "_, predictions1 = torch.max(Y_pred_good, 1)\n",
        "_, predictions2 = torch.max(Y_pred_bad, 1)\n",
        "print(f'Actual class: {Y.item()}, Y_pred1: {predictions1.item()}, Y_pred2: {predictions2.item()}')\n",
        "\n",
        "# allows batch loss for multiple samples\n",
        "\n",
        "# target is of size nBatch = 3\n",
        "# each element has class label: 0, 1, or 2\n",
        "Y = torch.tensor([2, 0, 1])\n",
        "\n",
        "# input is of size nBatch x nClasses = 3 x 3\n",
        "# Y_pred are logits (not softmax)\n",
        "Y_pred_good = torch.tensor(\n",
        "    [[0.1, 0.2, 3.9], # predict class 2\n",
        "    [1.2, 0.1, 0.3], # predict class 0\n",
        "    [0.3, 2.2, 0.2]]) # predict class 1\n",
        "\n",
        "Y_pred_bad = torch.tensor(\n",
        "    [[0.9, 0.2, 0.1],\n",
        "    [0.1, 0.3, 1.5],\n",
        "    [1.2, 0.2, 0.5]])\n",
        "\n",
        "l1 = loss(Y_pred_good, Y)\n",
        "l2 = loss(Y_pred_bad, Y)\n",
        "print(f'Batch Loss1:  {l1.item():.4f}')\n",
        "print(f'Batch Loss2: {l2.item():.4f}')\n",
        "\n",
        "# get predictions\n",
        "_, predictions1 = torch.max(Y_pred_good, 1)\n",
        "_, predictions2 = torch.max(Y_pred_bad, 1)\n",
        "print(f'Actual class: {Y}, Y_pred1: {predictions1}, Y_pred2: {predictions2}')\n",
        "\n",
        "# Binary classification\n",
        "class NeuralNet1(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(NeuralNet1, self).__init__()\n",
        "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.linear2 = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.linear1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.linear2(out)\n",
        "        # sigmoid at the end\n",
        "        y_pred = torch.sigmoid(out)\n",
        "        return y_pred\n",
        "\n",
        "model = NeuralNet1(input_size=28*28, hidden_size=5)\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# Multiclass problem\n",
        "class NeuralNet2(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(NeuralNet2, self).__init__()\n",
        "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.linear2 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.linear1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.linear2(out)\n",
        "        # no softmax at the end\n",
        "        return out\n",
        "\n",
        "model = NeuralNet2(input_size=28*28, hidden_size=5, num_classes=3)\n",
        "criterion = nn.CrossEntropyLoss()  # (applies Softmax)"
      ],
      "metadata": {
        "id": "ndUMvoRJDa9T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd094c45-4e69-4220-fac3-8c14c1df12ce"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "softmax numpy: [0.65900114 0.24243297 0.09856589]\n",
            "softmax torch: tensor([0.6590, 0.2424, 0.0986])\n",
            "Loss1 numpy: 0.3567\n",
            "Loss2 numpy: 2.3026\n",
            "PyTorch Loss1: 0.4170\n",
            "PyTorch Loss2: 1.8406\n",
            "Actual class: 0, Y_pred1: 0, Y_pred2: 1\n",
            "Batch Loss1:  0.2834\n",
            "Batch Loss2: 1.6418\n",
            "Actual class: tensor([2, 0, 1]), Y_pred1: tensor([2, 0, 1]), Y_pred2: tensor([0, 2, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Activation Functions"
      ],
      "metadata": {
        "id": "PKx8ZrZEDg_x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "x = torch.tensor([-1.0, 1.0, 2.0, 3.0])\n",
        "\n",
        "# sofmax\n",
        "output = torch.softmax(x, dim=0)\n",
        "print(output)\n",
        "sm = nn.Softmax(dim=0)\n",
        "output = sm(x)\n",
        "print(output)\n",
        "\n",
        "# sigmoid\n",
        "output = torch.sigmoid(x)\n",
        "print(output)\n",
        "s = nn.Sigmoid()\n",
        "output = s(x)\n",
        "print(output)\n",
        "\n",
        "#tanh\n",
        "output = torch.tanh(x)\n",
        "print(output)\n",
        "t = nn.Tanh()\n",
        "output = t(x)\n",
        "print(output)\n",
        "\n",
        "# relu\n",
        "output = torch.relu(x)\n",
        "print(output)\n",
        "relu = nn.ReLU()\n",
        "output = relu(x)\n",
        "print(output)\n",
        "\n",
        "# leaky relu\n",
        "output = F.leaky_relu(x)\n",
        "print(output)\n",
        "lrelu = nn.LeakyReLU()\n",
        "output = lrelu(x)\n",
        "print(output)\n",
        "\n",
        "#nn.ReLU() creates an nn.Module which you can add e.g. to an nn.Sequential model.\n",
        "#torch.relu on the other side is just the functional API call to the relu function,\n",
        "#so that you can add it e.g. in your forward method yourself.\n",
        "\n",
        "# option 1 (create nn modules)\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.linear2 = nn.Linear(hidden_size, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.linear1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.linear2(out)\n",
        "        out = self.sigmoid(out)\n",
        "        return out\n",
        "\n",
        "# option 2 (use activation functions directly in forward pass)\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
        "        self.linear2 = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.relu(self.linear1(x))\n",
        "        out = torch.sigmoid(self.linear2(out))\n",
        "        return out"
      ],
      "metadata": {
        "id": "GMui6nZ5Dkjt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75228df1-0d09-48fd-d7eb-d42a000798ce"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.0120, 0.0889, 0.2418, 0.6572])\n",
            "tensor([0.0120, 0.0889, 0.2418, 0.6572])\n",
            "tensor([0.2689, 0.7311, 0.8808, 0.9526])\n",
            "tensor([0.2689, 0.7311, 0.8808, 0.9526])\n",
            "tensor([-0.7616,  0.7616,  0.9640,  0.9951])\n",
            "tensor([-0.7616,  0.7616,  0.9640,  0.9951])\n",
            "tensor([0., 1., 2., 3.])\n",
            "tensor([0., 1., 2., 3.])\n",
            "tensor([-0.0100,  1.0000,  2.0000,  3.0000])\n",
            "tensor([-0.0100,  1.0000,  2.0000,  3.0000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feed Forward Net"
      ],
      "metadata": {
        "id": "SlrXiI0pDuqa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyper-parameters\n",
        "input_size = 784 # 28x28\n",
        "hidden_size = 500\n",
        "num_classes = 10\n",
        "num_epochs = 2\n",
        "batch_size = 100\n",
        "learning_rate = 0.001\n",
        "\n",
        "# MNIST dataset\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data',\n",
        "                                           train=True,\n",
        "                                           transform=transforms.ToTensor(),\n",
        "                                           download=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data',\n",
        "                                          train=False,\n",
        "                                          transform=transforms.ToTensor())\n",
        "\n",
        "# Data loader\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)\n",
        "\n",
        "examples = iter(test_loader)\n",
        "example_data, example_targets = next(examples)\n",
        "\n",
        "for i in range(6):\n",
        "    plt.subplot(2,3,i+1)\n",
        "    plt.imshow(example_data[i][0], cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "# Fully connected neural network with one hidden layer\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.l1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.l2 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.l1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.l2(out)\n",
        "        # no activation and no softmax at the end\n",
        "        return out\n",
        "\n",
        "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Train the model\n",
        "n_total_steps = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        # origin shape: [100, 1, 28, 28]\n",
        "        # resized: [100, 784]\n",
        "        images = images.reshape(-1, 28*28).to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i+1) % 100 == 0:\n",
        "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Test the model\n",
        "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
        "with torch.no_grad():\n",
        "    n_correct = 0\n",
        "    n_samples = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.reshape(-1, 28*28).to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        # max returns (value ,index)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        n_samples += labels.size(0)\n",
        "        n_correct += (predicted == labels).sum().item()\n",
        "\n",
        "    acc = 100.0 * n_correct / n_samples\n",
        "    print(f'Accuracy of the network on the 10000 test images: {acc} %')\n"
      ],
      "metadata": {
        "id": "_bzWve2xDwC8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 984
        },
        "outputId": "6bc7399e-55f3-46ed-9d54-2295633dcaae"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 9912422/9912422 [00:00<00:00, 87824196.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 28881/28881 [00:00<00:00, 89531185.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|| 1648877/1648877 [00:00<00:00, 25365362.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 4542/4542 [00:00<00:00, 16049308.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 6 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAGKCAYAAACsHiO8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAArp0lEQVR4nO3df3BV9ZnH8SfB5PIruTGB3JCFSGp/oEtFjQQi1GLNELVSkejW0dnF2hG1N24Rq7uowC5rNx2cwRYaYDuzgnVXYNCCgpaVCRDW3QSXFNqlYFYphThwg6zmJkTyw9zv/uF4bfwelnNzz/3ec07er5nzRz45557nxIfM48n3npuhlFICAABgSGa6CwAAAEMLwwcAADCK4QMAABjF8AEAAIxi+AAAAEYxfAAAAKMYPgAAgFEMHwAAwCiGDwAAYBTDBwAAMCplw0ddXZ1MnDhRhg8fLtOmTZO33347VacCHEXvwqvoXXhFRio+22Xz5s3yV3/1V7Ju3TqZNm2a/PSnP5UtW7ZIS0uLFBYW/r/HxmIxOXXqlOTk5EhGRobTpWGIUEpJZ2enFBcXS2am/Rmb3kW60bvwqoR6V6VAeXm5CofD8a/7+/tVcXGxqq2tveixra2tSkTY2BzZWltb6V02T270LptXNzu96/ifXXp7e6W5uVkqKyvjWWZmplRWVkpjY6O2f09Pj3R0dMQ3xYfswkE5OTm296V34Sb0LrzKTu86PnycPXtW+vv7JRQKDchDoZBEIhFt/9raWgkGg/GtpKTE6ZIwhCVyC5nehZvQu/AqO72b9ne7LF68WKLRaHxrbW1Nd0mALfQuvIreRbpd4vQLjhkzRoYNGyZtbW0D8ra2NikqKtL2DwQCEggEnC4DSBi9C6+id+E1jt/5yM7OlrKyMqmvr49nsVhM6uvrpaKiwunTAY6hd+FV9C48J6Hl1DZt2rRJBQIBtWHDBnXkyBG1YMEClZeXpyKRyEWPjUajaV+py+afLRqN0rtsntzoXTavbnZ6NyXDh1JKrV69WpWUlKjs7GxVXl6umpqabB3HPwI2J7dEf4HTu2xu2ehdNq9udno3JQ8ZS0ZHR4cEg8F0lwGfiEajkpuba+Rc9C6cRO/Cq+z0btrf7QIAAIYWhg8AAGAUwwcAADCK4QMAABjF8AEAAIxi+AAAAEYxfAAAAKMc/2wXAP7xox/9SMtGjBhhue9VV12lZXfeeaet86xdu1bLrD4KXkTkxRdftPWaANyLOx8AAMAohg8AAGAUwwcAADCK4QMAABjFglMAIiKyefNmLbO7YPRCYrGYrf0efPBBLausrLTct6GhQctOnjyZWGFACn31q1+1zN955x0t++EPf6hlq1evdrwmt+HOBwAAMIrhAwAAGMXwAQAAjGL4AAAARrHgFBiCUrG41Gox3b/9279p2Ze+9CUtmzNnjpZdfvnllue59957tay2ttZOiYAR11xzjWVutQD7/fffT3U5rsSdDwAAYBTDBwAAMIrhAwAAGMXwAQAAjGLBKeBj1113nWV+xx132Dr+97//vZZ95zvfsdz37NmzWnbu3Dkty87O1rKmpiYtmzJliuV5CgoKLHPALa6++mrLvKurS8u2bt2a4mrciTsfAADAKIYPAABgFMMHAAAwiuEDAAAYxYLTL7B6yuMDDzxgue+pU6e0rLu7W8v+9V//VcsikYjla7733nsXKxGwbdy4cZZ5RkaGllktLq2qqtKy06dPJ1XTY489pmVXXnml7eNff/31pM4POGny5MlaVlNTY7nviy++mOpyPIM7HwAAwCiGDwAAYBTDBwAAMIrhAwAAGMXwAQAAjOLdLl+wYsUKLZs4cWJSr/nggw9qWWdnp+W+Vu84cJv3339fy6x+biIiBw4cSHU5+H9s377dMv/yl7+sZVY9+eGHHzpe0913361lWVlZjp8HMGHSpElaNmrUKMt9N2/enOpyPIM7HwAAwCiGDwAAYBTDBwAAMIrhAwAAGMWC0y+wepT6VVddZbnv0aNHteyKK67QsmuvvVbLZs2aZfma06dP17LW1lYtmzBhguXxdn3yySda9sEHH2jZhR7P/UUnT560zFlw6k4nTpwwcp7HH39cy7761a/aOnb//v0J5UA6PPHEE1p2oX9f/D78HHc+AACAUQwfAADAqISHj3379smcOXOkuLhYMjIyZNu2bQO+r5SSpUuXyrhx42TEiBFSWVkp7777rlP1AoNG78Kr6F34TcLDR1dXl0yZMkXq6uosv79ixQpZtWqVrFu3Tvbv3y+jRo2Sqqoqy4+aB0yid+FV9C78JkMppQZ9cEaGbN26VebOnSsin07fxcXF8thjj8mPfvQjERGJRqMSCoVkw4YNlk82/KKOjg4JBoODLckzLr30Usv86quv1rLm5mYtmzp1alLnt/ql9D//8z9aZrWoNj8/X8vC4bDledauXTuI6pwTjUYlNzdXy+ld5912221atmXLFi3Lzs7WsjNnzmjZhX7mDQ0Ng6jOe+hd97F62vUf/vAHLbP6XSpi/TRUP7pQ7/4pR9d8HD9+XCKRiFRWVsazYDAo06ZNk8bGRidPBTiK3oVX0bvwIkffahuJREREJBQKDchDoVD8e1/U09MjPT098a87OjqcLAmwhd6FV9G78KK0v9ultrZWgsFgfEv2+RWAKfQuvIreRbo5OnwUFRWJiEhbW9uAvK2tLf69L1q8eLFEo9H4ZvVALSDV6F14Fb0LL3L0zy6lpaVSVFQk9fX18YWTHR0dsn//fnn44YctjwkEAhIIBJwswxM++ugjy3zPnj22jq+vr3eyHBERqa6u1jKrhbH//d//rWVe/6hoejd51113nZZZLS61YtU/Q2VhabLoXXO++c1v2trP6mnRGCjh4ePcuXPy3nvvxb8+fvy4HDp0SPLz86WkpEQWLlwozzzzjHzlK1+R0tJSWbJkiRQXF8dXZgPpQu/Cq+hd+E3Cw8eBAwfkxhtvjH+9aNEiERGZP3++bNiwQZ544gnp6uqSBQsWSHt7u8ycOVN27twpw4cPd65qYBDoXXgVvQu/SXj4mDVrlvx/jwbJyMiQ5cuXy/Lly5MqDHAavQuvonfhN2l/twsAABhaGD4AAIBRjr7bBd5RWFioZWvWrNGyzEx9PrW6tfvhhx86Uxhc74sfavaZ2bNn2zr+l7/8pZY9/fTTyZQEGPH1r3/d1n4rVqxIcSXex50PAABgFMMHAAAwiuEDAAAYxfABAACMYsHpEBUOh7Vs7NixWmb1GPiWlpaU1AT3GTdunJZdf/31lvtaPa777NmzWvbMM89o2blz5wZRHZA606dP17Lvfe97Wnbw4EEt27VrV0pq8hPufAAAAKMYPgAAgFEMHwAAwCiGDwAAYBQLTn1uxowZlvnf/u3f2jre6iO5Dx8+nExJ8JBXXnlFywoKCmwf/y//8i9aduzYsaRqAkyorKzUsvz8fC3buXOnlnV3d6ekJj/hzgcAADCK4QMAABjF8AEAAIxi+AAAAEax4NTnbr31Vss8KytLy+rr67WssbHR8ZrgTt/5zne07Nprr7V9/N69e7Vs2bJlyZQEpM2UKVO0TCmlZS+//LKJcnyHOx8AAMAohg8AAGAUwwcAADCK4QMAABjFglMfGTFihJbdfPPNlvv29vZqmdXiwL6+vuQLg+tYPaX0ySef1DKrhckXcujQIS07d+5cQnUB6VBUVKRl3/jGN7SspaVFy7Zu3ZqSmvyOOx8AAMAohg8AAGAUwwcAADCK4QMAABjF8AEAAIzi3S4+8vjjj2vZNddcY7nvzp07tew///M/Ha8J7vTYY49p2dSpU20du23bNsucR6nDq+677z4tKyws1LJf//rXBqoZGrjzAQAAjGL4AAAARjF8AAAAoxg+AACAUSw49ahvf/vbWrZkyRIt6+josDx++fLljtcE71i0aNGgj62pqbHMeZQ6vOqyyy6ztd9HH32U4kqGDu58AAAAoxg+AACAUQwfAADAKIYPAABgFAtOPaCgoEDLVq1apWXDhg3TsjfeeMPyNZuampIvDENSfn6+Zd7X1+foeaLRqO3zZGVlaVkwGLR1nry8PMs8mUW5/f39lvnf/M3faNnHH3886PPAGbfddput/bZv357iSoYO7nwAAACjGD4AAIBRCQ0ftbW1MnXqVMnJyZHCwkKZO3eutLS0DNinu7tbwuGwFBQUyOjRo6W6ulra2tocLRpIFL0Lr6J34UcJDR8NDQ0SDoelqalJdu3aJX19fTJ79mzp6uqK7/Poo4/K9u3bZcuWLdLQ0CCnTp2SefPmOV44kAh6F15F78KPMpRSarAHf/DBB1JYWCgNDQ1yww03SDQalbFjx8pLL70kd955p4iIvPPOO3LFFVdIY2OjTJ8+/aKv2dHRYXuhmB9ZLRq1WhxaVlamZceOHdOym2++2fI8Vvv6UTQaldzcXC0f6r3b3d2tZVaLNtNpy5Ytlvnp06e1LBQKadl3v/tdx2tK1tKlS7Xsxz/+seW+9K7zZs6caZnv2bNHy6x+F9900022jh3qLtS7fyqpNR+frUb/bPV7c3Oz9PX1SWVlZXyfSZMmSUlJiTQ2NiZzKsBR9C68it6FHwz6rbaxWEwWLlwoM2bMkMmTJ4uISCQSkezsbO2ta6FQSCKRiOXr9PT0SE9PT/zrC30WCeAUehdeRe/CLwZ95yMcDsvhw4dl06ZNSRVQW1srwWAwvk2YMCGp1wMuht6FV9G78ItBDR81NTWyY8cO2bNnj4wfPz6eFxUVSW9vr7S3tw/Yv62tTYqKiixfa/HixRKNRuNba2vrYEoCbKF34VX0LvwkoT+7KKXkkUceka1bt8revXultLR0wPfLysokKytL6uvrpbq6WkREWlpa5OTJk1JRUWH5moFAQAKBwCDL95/LL79cy6wWl1qxeiLjUFlYejH07kBWT769/fbb01DJhd11112Ov+Ynn3yiZbFYzPbxr732mpYdOHDA9vH//u//bnvfz9C7zrnjjjssc6vFpQcPHtSyffv2OV7TUJXQ8BEOh+Wll16SV199VXJycuJ/TwwGgzJixAgJBoPy/e9/XxYtWiT5+fmSm5srjzzyiFRUVNhacQ2kCr0Lr6J34UcJDR9r164VEZFZs2YNyNevXy/33XefiIg899xzkpmZKdXV1dLT0yNVVVWyZs0aR4oFBovehVfRu/CjhP/scjHDhw+Xuro6qaurG3RRgNPoXXgVvQs/4rNdAACAUQwfAADAqEE/ZAzJueyyyyzzN99809bxjz/+uJbt2LEjqZowdFh97scTTzyhZck+cv3P//zPtSzZx54///zzWvbHP/7R1rGvvPKKlr3zzjtJ1QN3GjlypJbdeuutto9/+eWXtay/vz+pmvA57nwAAACjGD4AAIBRDB8AAMAohg8AAGAUC07TZMGCBZZ5SUmJreMbGhq0zM7zAIALWbFihZHz3HPPPUbOg6Gtr69Pyz766CPLfa0em/+zn/3M8ZrwOe58AAAAoxg+AACAUQwfAADAKIYPAABgFAtODZg5c6aWPfLII2moBACGBqsFp9dff30aKoEV7nwAAACjGD4AAIBRDB8AAMAohg8AAGAUC04N+MY3vqFlo0ePtn38sWPHtOzcuXNJ1QQAQLpw5wMAABjF8AEAAIxi+AAAAEYxfAAAAKMYPgAAgFG828Vlfvvb32rZTTfdpGUffvihiXIAAHAcdz4AAIBRDB8AAMAohg8AAGAUwwcAADAqQyml0l3En+ro6JBgMJjuMuAT0WhUcnNzjZyL3oWT6F14lZ3e5c4HAAAwiuEDAAAYxfABAACMct3w4bIlKPA4k/1E78JJ9C68yk4/uW746OzsTHcJ8BGT/UTvwkn0LrzKTj+57t0usVhMTp06JTk5OdLZ2SkTJkyQ1tZWY6u+U6mjo4PrMUQpJZ2dnVJcXCyZmWZmbHrXO9x8PfSus9z833ow3Hw9ifSu6z7bJTMzU8aPHy8iIhkZGSIikpub67ofcjK4HjNMv3WQ3vUet14Pves8rscMu73ruj+7AAAAf2P4AAAARrl6+AgEArJs2TIJBALpLsURXM/Q4befDdczdPjtZ8P1uJPrFpwCAAB/c/WdDwAA4D8MHwAAwCiGDwAAYJRrh4+6ujqZOHGiDB8+XKZNmyZvv/12ukuybd++fTJnzhwpLi6WjIwM2bZt24DvK6Vk6dKlMm7cOBkxYoRUVlbKu+++m55iL6K2tlamTp0qOTk5UlhYKHPnzpWWlpYB+3R3d0s4HJaCggIZPXq0VFdXS1tbW5oqdgev9i+9S+/Su+7g9/515fCxefNmWbRokSxbtkx+85vfyJQpU6SqqkrOnDmT7tJs6erqkilTpkhdXZ3l91esWCGrVq2SdevWyf79+2XUqFFSVVUl3d3dhiu9uIaGBgmHw9LU1CS7du2Svr4+mT17tnR1dcX3efTRR2X79u2yZcsWaWhokFOnTsm8efPSWHV6ebl/6V16l951B9/3r3Kh8vJyFQ6H41/39/er4uJiVVtbm8aqBkdE1NatW+Nfx2IxVVRUpJ599tl41t7ergKBgNq4cWMaKkzMmTNnlIiohoYGpdSntWdlZaktW7bE9zl69KgSEdXY2JiuMtPKL/1L7w499K57+a1/XXfno7e3V5qbm6WysjKeZWZmSmVlpTQ2NqaxMmccP35cIpHIgOsLBoMybdo0T1xfNBoVEZH8/HwREWlubpa+vr4B1zNp0iQpKSnxxPU4zc/9S+/6G73rbn7rX9cNH2fPnpX+/n4JhUID8lAoJJFIJE1VOeeza/Di9cViMVm4cKHMmDFDJk+eLCKfXk92drbk5eUN2NcL15MKfu5fetff6F338mP/uu6D5eBe4XBYDh8+LG+99Va6SwESQu/Cy/zYv6678zFmzBgZNmyYtmK3ra1NioqK0lSVcz67Bq9dX01NjezYsUP27NkT//RLkU+vp7e3V9rb2wfs7/brSRU/9y+962/0rjv5tX9dN3xkZ2dLWVmZ1NfXx7NYLCb19fVSUVGRxsqcUVpaKkVFRQOur6OjQ/bv3+/K61NKSU1NjWzdulV2794tpaWlA75fVlYmWVlZA66npaVFTp486crrSTU/9y+962/0rrv4vn/TvODV0qZNm1QgEFAbNmxQR44cUQsWLFB5eXkqEomkuzRbOjs71cGDB9XBgweViKiVK1eqgwcPqhMnTiillPrJT36i8vLy1Kuvvqp+97vfqdtvv12Vlpaq8+fPp7ly3cMPP6yCwaDau3evOn36dHz7+OOP4/s89NBDqqSkRO3evVsdOHBAVVRUqIqKijRWnV5e7l96l96ld93B7/3ryuFDKaVWr16tSkpKVHZ2tiovL1dNTU3pLsm2PXv2KBHRtvnz5yulPn3b15IlS1QoFFKBQEDddNNNqqWlJb1FX4DVdYiIWr9+fXyf8+fPqx/84Afq0ksvVSNHjlR33HGHOn36dPqKdgGv9i+9S+/Su+7g9/7lU20BAIBRrlvzAQAA/I3hAwAAGMXwAQAAjGL4AAAARjF8AAAAoxg+AACAUQwfAADAKIYPAABgFMMHAAAwiuEDAAAYxfABAACMYvgAAABGMXwAAACjGD4AAIBRDB8AAMAohg8AAGAUwwcAADCK4QMAABjF8AEAAIxi+AAAAEYxfAAAAKMYPgAAgFEMHwAAwCiGDwAAYBTDBwAAMIrhAwAAGMXwAQAAjGL4AAAARjF8AAAAoxg+AACAUQwfAADAKIYPAABgFMMHAAAw6pJUvXBdXZ08++yzEolEZMqUKbJ69WopLy+/6HGxWExOnTolOTk5kpGRkary4HNKKens7JTi4mLJzExsxqZ3kU70Lrwqod5VKbBp0yaVnZ2tnn/+efX73/9ePfDAAyovL0+1tbVd9NjW1lYlImxsjmytra30LpsnN3qXzaubnd5NyfBRXl6uwuFw/Ov+/n5VXFysamtrL3pse3t72n9wbP7Z2tvb6V02T270LptXNzu96/iaj97eXmlubpbKysp4lpmZKZWVldLY2Kjt39PTIx0dHfGts7PT6ZIwhCVyC5nehZvQu/AqO73r+PBx9uxZ6e/vl1AoNCAPhUISiUS0/WtrayUYDMa3CRMmOF0SYAu9C6+id+E1aX+3y+LFiyUajca31tbWdJcE2ELvwqvoXaSb4+92GTNmjAwbNkza2toG5G1tbVJUVKTtHwgEJBAIOF0GkDB6F15F78JrHL/zkZ2dLWVlZVJfXx/PYrGY1NfXS0VFhdOnAxxD78Kr6F14TkLLqW3atGmTCgQCasOGDerIkSNqwYIFKi8vT0UikYseG41G075Sl80/WzQapXfZPLnRu2xe3ez0bkqGD6WUWr16tSopKVHZ2dmqvLxcNTU12TqOfwRsTm6J/gKnd9ncstG7bF7d7PRuhlJKiYt0dHRIMBhMdxnwiWg0Krm5uUbORe/CSfQuvMpO76b93S4AAGBoYfgAAABGMXwAAACjGD4AAIBRDB8AAMAohg8AAGAUwwcAADCK4QMAABjF8AEAAIxi+AAAAEYxfAAAAKMuSXcBGGjUqFFa9uyzz2rZgw8+qGXNzc1adtddd1me58SJE4OoDgCA5HHnAwAAGMXwAQAAjGL4AAAARjF8AAAAo1hw6jLjxo3TsgceeEDLYrGYlpWVlWnZbbfdZnmeurq6QVSHoebaa6/Vsl/96leW+06cODHF1SRm9uzZWnb06FEta21tNVEOhpA5c+ZY5q+99pqW1dTUaNm6deu0rL+/P/nCXIQ7HwAAwCiGDwAAYBTDBwAAMIrhAwAAGMWC0zQZO3asZf7CCy8YrgS4sKqqKi0LBAJpqCRxVov+7r//fi27++67TZQDnyooKNCyNWvW2D7+5z//uZY9//zzWnb+/PnECnM57nwAAACjGD4AAIBRDB8AAMAohg8AAGAUC04N+Ou//mstmzt3ruW+5eXljp77hhtusMwzM/W587e//a2W7du3z9F64F6XXKL/Orj11lvTUIkzmpubtWzRokVaNmrUKMvju7q6HK8J/mP1O3b8+PG2j9+4caOWdXd3J1WTF3DnAwAAGMXwAQAAjGL4AAAARjF8AAAAoxg+AACAUbzbxYDnnntOy2KxmJFzz5s3z3Z+4sQJLfvud7+rZVbvIoD33XjjjVpWUVGhZStWrDBRTtIuvfRSLbvyyiu1bOTIkZbH824XfJHVRws89dRTSb3miy++qGVKqaRe0wu48wEAAIxi+AAAAEYxfAAAAKMYPgAAgFEsOHXYG2+8oWVWjzJPhf/93//VsnPnzlnue9lll2lZaWmplr399ttaNmzYsEFUBzeZPHmyllk95vnYsWNa9o//+I8pqclpt99+e7pLgM98/etf17KysjLbx3/yySda9utf/zqpmryKOx8AAMAohg8AAGAUwwcAADAq4eFj3759MmfOHCkuLpaMjAzZtm3bgO8rpWTp0qUybtw4GTFihFRWVsq7777rVL3AoNG78Cp6F36T8ILTrq4umTJlitx///2WT8lcsWKFrFq1Sl544QUpLS2VJUuWSFVVlRw5ckSGDx/uSNFu8c1vflPLvva1r2mZ1dNMk33C6bp167TszTff1LJoNGp5/Le+9S0ts/ukvocffljL1q5da+vYdKJ3P/f0009r2ahRo7Ts5ptv1rILLWJOp/z8fC2z+vdp6snCTqN33aG6ujqp461+Rw9VCQ8ft9xyi9xyyy2W31NKyU9/+lN5+umn4yvNf/nLX0ooFJJt27bJ3XffnVy1QBLoXXgVvQu/cXTNx/HjxyUSiUhlZWU8CwaDMm3aNGlsbLQ8pqenRzo6OgZsgGn0LryK3oUXOTp8RCIREREJhUID8lAoFP/eF9XW1kowGIxvEyZMcLIkwBZ6F15F78KL0v5ul8WLF0s0Go1vra2t6S4JsIXehVfRu0g3R59wWlRUJCIibW1tMm7cuHje1tYmV199teUxgUDA8mOK3WTixImW+aZNm7RszJgxSZ3L6mPtX3nlFS37+7//ey37+OOPkzrPggULtGzs2LFaZvWR6hda1Pbzn/9cy/r6+uyUaJRfe/fOO++0zG+99VYte++997TswIEDjteUClaLpa0Wl+7du1fL2tvbU1CROX7tXTe64YYbbO3X29trmdtd1D8UOHrno7S0VIqKiqS+vj6edXR0yP79+6WiosLJUwGOonfhVfQuvCjhOx/nzp0b8H9Ix48fl0OHDkl+fr6UlJTIwoUL5ZlnnpGvfOUr8bd8FRcXy9y5c52sG0gYvQuvonfhNwkPHwcOHJAbb7wx/vWiRYtERGT+/PmyYcMGeeKJJ6Srq0sWLFgg7e3tMnPmTNm5cyfvNUfa0bvwKnoXfpPw8DFr1ixRSl3w+xkZGbJ8+XJZvnx5UoUBTqN34VX0Lvwm7e92AQAAQ4uj73bxq0susf4xJfPOloaGBsvc6mmEZ8+eHfR5LsTq3S61tbVatnLlSi0bOXKkllm9A0ZE5LXXXtOyY8eO2SkRDrjrrrssc6v/hmvWrEl1OY6wevfZvffeq2X9/f1a9swzz2iZG999hfS7/vrrbWVWurq6LPNDhw4lU5KvcOcDAAAYxfABAACMYvgAAABGMXwAAACjWHBqgNUjqu+//37LfVOxuNQuq8WhVgv5pk6daqIcJCgYDGrZ9OnTbR+/du1aJ8tJGauPAbBa/H306FEt27NnT0pqgv8k83vOK/+W0ok7HwAAwCiGDwAAYBTDBwAAMIrhAwAAGMWC0yRkZtqb3aZNm5biSpyRkZGhZVbXaPe6RUT+7u/+Tsv+8i//MqG6YE8gENCyP/uzP7Pcd+PGjakuJ2Uuv/xyW/sdPnw4xZXAz6677jpb+7W3t2sZC04vjjsfAADAKIYPAABgFMMHAAAwiuEDAAAYxYJTGx566CHLPBaLGa4ktebMmaNl11xzjZZZXfeFfhZWC06RGp2dnVp2oY/wvuqqq7QsPz9fyz788MOk6xqswsJCy/zOO++0dfxbb73lZDnwsZkzZ2rZPffcY+vYaDSqZe+//37SNfkddz4AAIBRDB8AAMAohg8AAGAUwwcAADCKBac2WC3E9IqxY8da5ldeeaWWPfnkk4M+zwcffGCZ9/X1Dfo1kZjz589r2bFjxyz3ra6u1rLXX39dy1auXJl8YV8wefJkLfvSl76kZRMnTrQ8Xill6zx+WxCO1CkoKNAyu09y3rVrl9PlDAnc+QAAAEYxfAAAAKMYPgAAgFEMHwAAwCiGDwAAYBTvdvG5p556yjIPh8ODfs0//vGPWjZ//nzLfU+ePDno8yB5y5Yts8wzMjK07Nvf/raWbdy40fGazp49q2VW72AZM2ZMUufZsGFDUsdj6LD7yP729nYt+6d/+ieHqxkauPMBAACMYvgAAABGMXwAAACjGD4AAIBRLDj1kTfeeEPLvva1rzl+niNHjmjZW2+95fh5kLx33nnHMv+Lv/gLLbv66qu17Mtf/rLTJcnLL79sa78XXnjBMr/33nttHW/1uHkMbePHj7fM77nnHlvHv//++1p24MCBpGoaqrjzAQAAjGL4AAAARjF8AAAAoxg+AACAUSw4tcHqaZAiIpmZ9ma3W265xfa5fvGLX2hZcXGxrWOt6onFYrbPbdecOXMcf02k36FDh2xlpvzhD39I6vjJkydr2eHDh5N6TXjb9ddfb5nb/V2+bds2B6sZ2rjzAQAAjGL4AAAARjF8AAAAoxIaPmpra2Xq1KmSk5MjhYWFMnfuXGlpaRmwT3d3t4TDYSkoKJDRo0dLdXW1tLW1OVo0kCh6F15F78KPElpw2tDQIOFwWKZOnSqffPKJPPnkkzJ79mw5cuSIjBo1SkREHn30UXn99ddly5YtEgwGpaamRubNmyf/8R//kZILMGHt2rWW+YoVK2wdv2PHDi1LZCFoMotGk11wum7duqSOd4uh2rtedqGF3hfKv8gvi0vpXecUFBTY3vfs2bNa9rOf/czJcoa0hIaPnTt3Dvh6w4YNUlhYKM3NzXLDDTdINBqVf/7nf5aXXnpJvvWtb4mIyPr16+WKK66QpqYmmT59unOVAwmgd+FV9C78KKk1H9FoVERE8vPzRUSkublZ+vr6pLKyMr7PpEmTpKSkRBobGy1fo6enRzo6OgZsQKrRu/Aqehd+MOjhIxaLycKFC2XGjBnx99NHIhHJzs6WvLy8AfuGQiGJRCKWr1NbWyvBYDC+TZgwYbAlAbbQu/Aqehd+MejhIxwOy+HDh2XTpk1JFbB48WKJRqPxrbW1NanXAy6G3oVX0bvwi0E94bSmpkZ27Ngh+/btG/ARxUVFRdLb2yvt7e0DpvC2tjYpKiqyfK1AICCBQGAwZRjzq1/9yjJ//PHHtWzs2LGpLichH3zwgWV+9OhRLVuwYIGWnT592vGa0mmo9a6XKaUSyv2O3k1eVVWV7X1PnjypZZ/9yQvJS+jOh1JKampqZOvWrbJ7924pLS0d8P2ysjLJysqS+vr6eNbS0iInT56UiooKZyoGBoHehVfRu/CjhO58hMNheemll+TVV1+VnJyc+N8Tg8GgjBgxQoLBoHz/+9+XRYsWSX5+vuTm5sojjzwiFRUVrLhGWtG78Cp6F36U0PDx2fMuZs2aNSBfv3693HfffSIi8txzz0lmZqZUV1dLT0+PVFVVyZo1axwpFhgsehdeRe/CjxIaPuz8rXX48OFSV1cndXV1gy4KcBq9C6+id+FHfLYLAAAwalDvdhlqTpw4YZnffffdWjZ37lwt++EPf+h0Sbb9+Mc/tsz5PyS43fDhw23ve/78+RRWAi/KysrSsssvv9z28d3d3VrW19eXVE34HHc+AACAUQwfAADAKIYPAABgFMMHAAAwigWnSdi3b5+t7M0339Qyq0eZi4jMmTNHy1577TUt+8UvfqFlGRkZWnbkyBHL8wBu973vfc8yb29v17J/+Id/SHE18JpYLKZlBw4csNz3sw/p+1Pvvfee4zXhc9z5AAAARjF8AAAAoxg+AACAUQwfAADAKBacGrBz505bGYDP/dd//ZdlvnLlSi3bs2dPqsuBx/T392vZU089Zbmv1efnNDc3O14TPsedDwAAYBTDBwAAMIrhAwAAGMXwAQAAjMpQVitt0qijo0OCwWC6y4BPRKNRyc3NNXIuehdOonfhVXZ6lzsfAADAKIYPAABgFMMHAAAwiuEDAAAYxfABAACMYvgAAABGMXwAAACjGD4AAIBRDB8AAMAohg8AAGAUwwcAADCK4QMAABjF8AEAAIxi+AAAAEa5bvhQSqW7BPiIyX6id+EkehdeZaefXDd8dHZ2prsE+IjJfqJ34SR6F15lp58ylMtG3lgsJqdOnZKcnBzp7OyUCRMmSGtrq+Tm5qa7tKR1dHRwPYYopaSzs1OKi4slM9PMjE3veoebr4fedZab/1sPhpuvJ5HevcRQTbZlZmbK+PHjRUQkIyNDRERyc3Nd90NOBtdjRjAYNHo+etd73Ho99K7zuB4z7Pau6/7sAgAA/I3hAwAAGOXq4SMQCMiyZcskEAikuxRHcD1Dh99+NlzP0OG3nw3X406uW3AKAAD8zdV3PgAAgP8wfAAAAKMYPgAAgFEMHwAAwCjXDh91dXUyceJEGT58uEybNk3efvvtdJdk2759+2TOnDlSXFwsGRkZsm3btgHfV0rJ0qVLZdy4cTJixAiprKyUd999Nz3FXkRtba1MnTpVcnJypLCwUObOnSstLS0D9unu7pZwOCwFBQUyevRoqa6ulra2tjRV7A5e7V96l96ld93B7/3ryuFj8+bNsmjRIlm2bJn85je/kSlTpkhVVZWcOXMm3aXZ0tXVJVOmTJG6ujrL769YsUJWrVol69atk/3798uoUaOkqqpKuru7DVd6cQ0NDRIOh6WpqUl27dolfX19Mnv2bOnq6orv8+ijj8r27dtly5Yt0tDQIKdOnZJ58+alser08nL/0rv0Lr3rDr7vX+VC5eXlKhwOx7/u7+9XxcXFqra2No1VDY6IqK1bt8a/jsViqqioSD377LPxrL29XQUCAbVx48Y0VJiYM2fOKBFRDQ0NSqlPa8/KylJbtmyJ73P06FElIqqxsTFdZaaVX/qX3h166F338lv/uu7OR29vrzQ3N0tlZWU8y8zMlMrKSmlsbExjZc44fvy4RCKRAdcXDAZl2rRpnri+aDQqIiL5+fkiItLc3Cx9fX0DrmfSpElSUlLiietxmp/7l971N3rX3fzWv64bPs6ePSv9/f0SCoUG5KFQSCKRSJqqcs5n1+DF64vFYrJw4UKZMWOGTJ48WUQ+vZ7s7GzJy8sbsK8XricV/Ny/9K6/0bvu5cf+dd2n2sK9wuGwHD58WN566610lwIkhN6Fl/mxf11352PMmDEybNgwbcVuW1ubFBUVpakq53x2DV67vpqaGtmxY4fs2bMn/tHbIp9eT29vr7S3tw/Y3+3Xkyp+7l9619/oXXfya/+6bvjIzs6WsrIyqa+vj2exWEzq6+uloqIijZU5o7S0VIqKigZcX0dHh+zfv9+V16eUkpqaGtm6davs3r1bSktLB3y/rKxMsrKyBlxPS0uLnDx50pXXk2p+7l9619/oXXfxff+mecGrpU2bNqlAIKA2bNigjhw5ohYsWKDy8vJUJBJJd2m2dHZ2qoMHD6qDBw8qEVErV65UBw8eVCdOnFBKKfWTn/xE5eXlqVdffVX97ne/U7fffrsqLS1V58+fT3PluocfflgFg0G1d+9edfr06fj28ccfx/d56KGHVElJidq9e7c6cOCAqqioUBUVFWmsOr283L/0Lr1L77qD3/vXlcOHUkqtXr1alZSUqOzsbFVeXq6amprSXZJte/bsUSKibfPnz1dKffq2ryVLlqhQKKQCgYC66aabVEtLS3qLvgCr6xARtX79+vg+58+fVz/4wQ/UpZdeqkaOHKnuuOMOdfr06fQV7QJe7V96l96ld93B7/2boZRSqb23AgAA8DnXrfkAAAD+xvABAACMYvgAAABGMXwAAACjGD4AAIBRDB8AAMAohg8AAGAUwwcAADCK4QMAABjF8AEAAIxi+AAAAEYxfAAAAKP+D468C4doVUjtAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/2], Step [100/600], Loss: 0.3543\n",
            "Epoch [1/2], Step [200/600], Loss: 0.0899\n",
            "Epoch [1/2], Step [300/600], Loss: 0.2025\n",
            "Epoch [1/2], Step [400/600], Loss: 0.3377\n",
            "Epoch [1/2], Step [500/600], Loss: 0.1453\n",
            "Epoch [1/2], Step [600/600], Loss: 0.1566\n",
            "Epoch [2/2], Step [100/600], Loss: 0.1311\n",
            "Epoch [2/2], Step [200/600], Loss: 0.1173\n",
            "Epoch [2/2], Step [300/600], Loss: 0.0819\n",
            "Epoch [2/2], Step [400/600], Loss: 0.0589\n",
            "Epoch [2/2], Step [500/600], Loss: 0.1034\n",
            "Epoch [2/2], Step [600/600], Loss: 0.1653\n",
            "Accuracy of the network on the 10000 test images: 96.87 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN"
      ],
      "metadata": {
        "id": "KtxiPWB4Dy5x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyper-parameters\n",
        "num_epochs = 5\n",
        "batch_size = 4\n",
        "learning_rate = 0.001\n",
        "\n",
        "# dataset has PILImage images of range [0, 1].\n",
        "# We transform them to Tensors of normalized range [-1, 1]\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "# CIFAR10: 60000 32x32 color images in 10 classes, with 6000 images per class\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
        "                                          shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
        "                                         shuffle=False)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5  # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # -> n, 3, 32, 32\n",
        "        x = self.pool(F.relu(self.conv1(x)))  # -> n, 6, 14, 14\n",
        "        x = self.pool(F.relu(self.conv2(x)))  # -> n, 16, 5, 5\n",
        "        x = x.view(-1, 16 * 5 * 5)            # -> n, 400\n",
        "        x = F.relu(self.fc1(x))               # -> n, 120\n",
        "        x = F.relu(self.fc2(x))               # -> n, 84\n",
        "        x = self.fc3(x)                       # -> n, 10\n",
        "        return x\n",
        "\n",
        "\n",
        "model = ConvNet().to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "n_total_steps = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        # origin shape: [4, 3, 32, 32] = 4, 3, 1024\n",
        "        # input_layer: 3 input channels, 6 output channels, 5 kernel size\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i+1) % 2000 == 0:\n",
        "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
        "\n",
        "print('Finished Training')\n",
        "PATH = './cnn.pth'\n",
        "torch.save(model.state_dict(), PATH)\n",
        "\n",
        "with torch.no_grad():\n",
        "    n_correct = 0\n",
        "    n_samples = 0\n",
        "    n_class_correct = [0 for i in range(10)]\n",
        "    n_class_samples = [0 for i in range(10)]\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        # max returns (value ,index)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        n_samples += labels.size(0)\n",
        "        n_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        for i in range(batch_size):\n",
        "            label = labels[i]\n",
        "            pred = predicted[i]\n",
        "            if (label == pred):\n",
        "                n_class_correct[label] += 1\n",
        "            n_class_samples[label] += 1\n",
        "\n",
        "    acc = 100.0 * n_correct / n_samples\n",
        "    print(f'Accuracy of the network: {acc} %')\n",
        "\n",
        "    for i in range(10):\n",
        "        acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
        "        print(f'Accuracy of {classes[i]}: {acc} %')"
      ],
      "metadata": {
        "id": "nOxi_SFVD0NP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 991
        },
        "outputId": "efde035a-54e0-4788-e300-eb1fa0c2610d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 170498071/170498071 [00:02<00:00, 78106351.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Step [2000/12500], Loss: 2.3159\n",
            "Epoch [1/5], Step [4000/12500], Loss: 2.3172\n",
            "Epoch [1/5], Step [6000/12500], Loss: 2.2966\n",
            "Epoch [1/5], Step [8000/12500], Loss: 2.3011\n",
            "Epoch [1/5], Step [10000/12500], Loss: 2.2718\n",
            "Epoch [1/5], Step [12000/12500], Loss: 2.2859\n",
            "Epoch [2/5], Step [2000/12500], Loss: 2.1384\n",
            "Epoch [2/5], Step [4000/12500], Loss: 1.8586\n",
            "Epoch [2/5], Step [6000/12500], Loss: 2.1377\n",
            "Epoch [2/5], Step [8000/12500], Loss: 2.0889\n",
            "Epoch [2/5], Step [10000/12500], Loss: 1.7240\n",
            "Epoch [2/5], Step [12000/12500], Loss: 2.7519\n",
            "Epoch [3/5], Step [2000/12500], Loss: 1.3380\n",
            "Epoch [3/5], Step [4000/12500], Loss: 1.7564\n",
            "Epoch [3/5], Step [6000/12500], Loss: 2.1859\n",
            "Epoch [3/5], Step [8000/12500], Loss: 1.9437\n",
            "Epoch [3/5], Step [10000/12500], Loss: 0.8222\n",
            "Epoch [3/5], Step [12000/12500], Loss: 1.3060\n",
            "Epoch [4/5], Step [2000/12500], Loss: 1.9414\n",
            "Epoch [4/5], Step [4000/12500], Loss: 1.3637\n",
            "Epoch [4/5], Step [6000/12500], Loss: 1.6263\n",
            "Epoch [4/5], Step [8000/12500], Loss: 1.9128\n",
            "Epoch [4/5], Step [10000/12500], Loss: 1.3064\n",
            "Epoch [4/5], Step [12000/12500], Loss: 1.0161\n",
            "Epoch [5/5], Step [2000/12500], Loss: 1.4809\n",
            "Epoch [5/5], Step [4000/12500], Loss: 2.5216\n",
            "Epoch [5/5], Step [6000/12500], Loss: 1.2828\n",
            "Epoch [5/5], Step [8000/12500], Loss: 1.2893\n",
            "Epoch [5/5], Step [10000/12500], Loss: 1.6249\n",
            "Epoch [5/5], Step [12000/12500], Loss: 2.1411\n",
            "Finished Training\n",
            "Accuracy of the network: 49.27 %\n",
            "Accuracy of plane: 47.7 %\n",
            "Accuracy of car: 47.6 %\n",
            "Accuracy of bird: 34.1 %\n",
            "Accuracy of cat: 26.7 %\n",
            "Accuracy of deer: 33.5 %\n",
            "Accuracy of dog: 55.5 %\n",
            "Accuracy of frog: 64.9 %\n",
            "Accuracy of horse: 57.5 %\n",
            "Accuracy of ship: 66.9 %\n",
            "Accuracy of truck: 58.3 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transfer Learning"
      ],
      "metadata": {
        "id": "2tvo3hDCD5DK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import zipfile\n",
        "\n",
        "zip_path = '/content/hymenoptera_data.zip'\n",
        "extract_path = '/content/data'\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "\n",
        "mean = np.array([0.5, 0.5, 0.5])\n",
        "std = np.array([0.25, 0.25, 0.25])\n",
        "\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean, std)\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean, std)\n",
        "    ]),\n",
        "}\n",
        "\n",
        "data_dir = '/content/data/hymenoptera_data'\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
        "                                          data_transforms[x])\n",
        "                  for x in ['train', 'val']}\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
        "                                             shuffle=True, num_workers=0)\n",
        "              for x in ['train', 'val']}\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "class_names = image_datasets['train'].classes\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(class_names)\n",
        "\n",
        "\n",
        "def imshow(inp, title):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp)\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Get a batch of training data\n",
        "inputs, classes = next(iter(dataloaders['train']))\n",
        "\n",
        "# Make a grid from batch\n",
        "out = torchvision.utils.make_grid(inputs)\n",
        "\n",
        "imshow(out, title=[class_names[x] for x in classes])\n",
        "\n",
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        optimizer.zero_grad()\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model\n",
        "\n",
        "\n",
        "#### Finetuning the convnet ####\n",
        "# Load a pretrained model and reset final fully connected layer.\n",
        "\n",
        "model = models.resnet18(pretrained=True)\n",
        "num_ftrs = model.fc.in_features\n",
        "# Here the size of each output sample is set to 2.\n",
        "# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
        "model.fc = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
        "\n",
        "# StepLR Decays the learning rate of each parameter group by gamma every step_size epochs\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "# Learning rate scheduling should be applied after optimizers update\n",
        "# e.g., you should write your code this way:\n",
        "# for epoch in range(100):\n",
        "#     train(...)\n",
        "#     validate(...)\n",
        "#     scheduler.step()\n",
        "\n",
        "step_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
        "\n",
        "model = train_model(model, criterion, optimizer, step_lr_scheduler, num_epochs=25)\n",
        "\n",
        "\n",
        "#### ConvNet as fixed feature extractor ####\n",
        "# Here, we need to freeze all the network except the final layer.\n",
        "# We need to set requires_grad == False to freeze the parameters so that the gradients are not computed in backward()\n",
        "model_conv = torchvision.models.resnet18(pretrained=True)\n",
        "for param in model_conv.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Parameters of newly constructed modules have requires_grad=True by default\n",
        "num_ftrs = model_conv.fc.in_features\n",
        "model_conv.fc = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "model_conv = model_conv.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that only parameters of final layer are being optimized as\n",
        "# opposed to before.\n",
        "optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)\n",
        "\n",
        "model_conv = train_model(model_conv, criterion, optimizer_conv,\n",
        "                         exp_lr_scheduler, num_epochs=25)"
      ],
      "metadata": {
        "id": "4WKjcxdqD7MQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "bd09cbdf-1587-4573-dec5-0b5d9eca3386"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-2510e65572d3>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mextract_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/data'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mzip_ref\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mzip_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps)\u001b[0m\n\u001b[1;32m   1249\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1251\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/hymenoptera_data.zip'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TensorBoard"
      ],
      "metadata": {
        "id": "8m0K_StnD_c9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "############## TENSORBOARD ########################\n",
        "import sys\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "# default `log_dir` is \"runs\" - we'll be more specific here\n",
        "writer = SummaryWriter('runs/mnist1')\n",
        "###################################################\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyper-parameters\n",
        "input_size = 784 # 28x28\n",
        "hidden_size = 500\n",
        "num_classes = 10\n",
        "num_epochs = 1\n",
        "batch_size = 64\n",
        "learning_rate = 0.001\n",
        "\n",
        "# MNIST dataset\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data',\n",
        "                                           train=True,\n",
        "                                           transform=transforms.ToTensor(),\n",
        "                                           download=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data',\n",
        "                                          train=False,\n",
        "                                          transform=transforms.ToTensor())\n",
        "\n",
        "# Data loader\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)\n",
        "\n",
        "examples = iter(test_loader)\n",
        "example_data, example_targets = next(examples)\n",
        "\n",
        "for i in range(6):\n",
        "    plt.subplot(2,3,i+1)\n",
        "    plt.imshow(example_data[i][0], cmap='gray')\n",
        "#plt.show()\n",
        "\n",
        "############## TENSORBOARD ########################\n",
        "img_grid = torchvision.utils.make_grid(example_data)\n",
        "writer.add_image('mnist_images', img_grid)\n",
        "#writer.close()\n",
        "#sys.exit()\n",
        "###################################################\n",
        "\n",
        "# Fully connected neural network with one hidden layer\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.l1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.l2 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.l1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.l2(out)\n",
        "        # no activation and no softmax at the end\n",
        "        return out\n",
        "\n",
        "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "############## TENSORBOARD ########################\n",
        "writer.add_graph(model, example_data.reshape(-1, 28*28).to(device))\n",
        "#writer.close()\n",
        "#sys.exit()\n",
        "###################################################\n",
        "\n",
        "# Train the model\n",
        "running_loss = 0.0\n",
        "running_correct = 0\n",
        "n_total_steps = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        # origin shape: [100, 1, 28, 28]\n",
        "        # resized: [100, 784]\n",
        "        images = images.reshape(-1, 28*28).to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        running_correct += (predicted == labels).sum().item()\n",
        "        if (i+1) % 100 == 0:\n",
        "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
        "            ############## TENSORBOARD ########################\n",
        "            writer.add_scalar('training loss', running_loss / 100, epoch * n_total_steps + i)\n",
        "            running_accuracy = running_correct / 100 / predicted.size(0)\n",
        "            writer.add_scalar('accuracy', running_accuracy, epoch * n_total_steps + i)\n",
        "            running_correct = 0\n",
        "            running_loss = 0.0\n",
        "            ###################################################\n",
        "\n",
        "# Test the model\n",
        "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
        "class_labels = []\n",
        "class_preds = []\n",
        "with torch.no_grad():\n",
        "    n_correct = 0\n",
        "    n_samples = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.reshape(-1, 28*28).to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        # max returns (value ,index)\n",
        "        values, predicted = torch.max(outputs.data, 1)\n",
        "        n_samples += labels.size(0)\n",
        "        n_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        class_probs_batch = [F.softmax(output, dim=0) for output in outputs]\n",
        "\n",
        "        class_preds.append(class_probs_batch)\n",
        "        class_labels.append(labels)\n",
        "\n",
        "    # 10000, 10, and 10000, 1\n",
        "    # stack concatenates tensors along a new dimension\n",
        "    # cat concatenates tensors in the given dimension\n",
        "    class_preds = torch.cat([torch.stack(batch) for batch in class_preds])\n",
        "    class_labels = torch.cat(class_labels)\n",
        "\n",
        "    acc = 100.0 * n_correct / n_samples\n",
        "    print(f'Accuracy of the network on the 10000 test images: {acc} %')\n",
        "\n",
        "    ############## TENSORBOARD ########################\n",
        "    classes = range(10)\n",
        "    for i in classes:\n",
        "        labels_i = class_labels == i\n",
        "        preds_i = class_preds[:, i]\n",
        "        writer.add_pr_curve(str(i), labels_i, preds_i, global_step=0)\n",
        "        writer.close()\n",
        "    ###################################################"
      ],
      "metadata": {
        "id": "PauQLAd0EHCw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 585
        },
        "outputId": "3caefd4f-5b46-4303-f4ef-b7e57f844751"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/1], Step [100/938], Loss: 0.3761\n",
            "Epoch [1/1], Step [200/938], Loss: 0.2379\n",
            "Epoch [1/1], Step [300/938], Loss: 0.3310\n",
            "Epoch [1/1], Step [400/938], Loss: 0.2278\n",
            "Epoch [1/1], Step [500/938], Loss: 0.1831\n",
            "Epoch [1/1], Step [600/938], Loss: 0.1137\n",
            "Epoch [1/1], Step [700/938], Loss: 0.1101\n",
            "Epoch [1/1], Step [800/938], Loss: 0.1986\n",
            "Epoch [1/1], Step [900/938], Loss: 0.0504\n",
            "Accuracy of the network on the 10000 test images: 96.22 %\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 6 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save n Load Models"
      ],
      "metadata": {
        "id": "Sxm7xAfsEITT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, n_input_features):\n",
        "        super(Model, self).__init__()\n",
        "        self.linear = nn.Linear(n_input_features, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        y_pred = torch.sigmoid(self.linear(x))\n",
        "        return y_pred\n",
        "\n",
        "model = Model(n_input_features=6)\n",
        "# train your model...\n",
        "\n",
        "####################save all ######################################\n",
        "for param in model.parameters():\n",
        "    print(param)\n",
        "\n",
        "# save and load entire model\n",
        "\n",
        "FILE = \"model.pth\"\n",
        "torch.save(model, FILE)\n",
        "\n",
        "loaded_model = torch.load(FILE)\n",
        "loaded_model.eval()\n",
        "\n",
        "for param in loaded_model.parameters():\n",
        "    print(param)\n",
        "\n",
        "\n",
        "############save only state dict #########################\n",
        "\n",
        "# save only state dict\n",
        "FILE = \"model.pth\"\n",
        "torch.save(model.state_dict(), FILE)\n",
        "\n",
        "print(model.state_dict())\n",
        "loaded_model = Model(n_input_features=6)\n",
        "loaded_model.load_state_dict(torch.load(FILE)) # it takes the loaded dictionary, not the path file itself\n",
        "loaded_model.eval()\n",
        "\n",
        "print(loaded_model.state_dict())\n",
        "\n",
        "\n",
        "###########load checkpoint#####################\n",
        "learning_rate = 0.01\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "checkpoint = {\n",
        "\"epoch\": 90,\n",
        "\"model_state\": model.state_dict(),\n",
        "\"optim_state\": optimizer.state_dict()\n",
        "}\n",
        "print(optimizer.state_dict())\n",
        "FILE = \"checkpoint.pth\"\n",
        "torch.save(checkpoint, FILE)\n",
        "\n",
        "model = Model(n_input_features=6)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0)\n",
        "\n",
        "checkpoint = torch.load(FILE)\n",
        "model.load_state_dict(checkpoint['model_state'])\n",
        "optimizer.load_state_dict(checkpoint['optim_state'])\n",
        "epoch = checkpoint['epoch']\n",
        "\n",
        "model.eval()\n",
        "# - or -\n",
        "# model.train()\n",
        "\n",
        "print(optimizer.state_dict())\n"
      ],
      "metadata": {
        "id": "XuavUvOqELMJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f409243-ec36-43d8-c422-c4871d849586"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.2895,  0.2301,  0.0892, -0.3599, -0.3338, -0.1142]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0390], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.2895,  0.2301,  0.0892, -0.3599, -0.3338, -0.1142]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0390], requires_grad=True)\n",
            "OrderedDict([('linear.weight', tensor([[-0.2895,  0.2301,  0.0892, -0.3599, -0.3338, -0.1142]])), ('linear.bias', tensor([-0.0390]))])\n",
            "OrderedDict([('linear.weight', tensor([[-0.2895,  0.2301,  0.0892, -0.3599, -0.3338, -0.1142]])), ('linear.bias', tensor([-0.0390]))])\n",
            "{'state': {}, 'param_groups': [{'lr': 0.01, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'maximize': False, 'foreach': None, 'differentiable': False, 'params': [0, 1]}]}\n",
            "{'state': {}, 'param_groups': [{'lr': 0.01, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'maximize': False, 'foreach': None, 'differentiable': False, 'params': [0, 1]}]}\n"
          ]
        }
      ]
    }
  ]
}